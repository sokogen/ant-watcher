1. Общая архитектура и хранение метрик

    Основное хранилище: Буду передавать данные в кластер VictoriaMetrics для хранения метрик. Он оптимально подходит для работы с временными рядами, имеет встроенную поддержку дедупликации данных, и хорошо интегрируется с Grafana для визуализации.

    Выбор подхода к обработке данных:
        Гибридный подход: Планирую использовать временные объекты для хранения состояния воркфлоу и джобов во время их обработки, но после отправки метрик в VictoriaMetrics очищать их из оперативной памяти (скорее всего по TTL и по заполнению доступной памяти с выкидыванием error при чистке по недоступности памяти).
        API и вебхуки: Данные будут собираться из двух источников — вебхуков (основной, в реальном времени) и GitHub API (после рестартов), чтобы добрать пропущенные метрики. Вебхуки как простые, так и с использование Github app. API для добора пропущенных метрик после рестарта или других инцидентов. Для обращения к API буду использовать сначала App, а потом OAuth2 (в случае исчерпания лимита запросов для первого).
        Будет использоваться асинхронная обработка данных, планирую использовать очереди или процессы для обработки данных из вебхуков и API.
        Сервис будет поддерживать два варианта отправки данных в систему хранения метрик: через /metrics и /push API (пока думаю про это). При этом, при успешной отправке данных в VictoriaMetrics, данные должны будут вычищаться из памяти, но только в случае полной отправки всех данных объектов, многие воркфлоу имеют большую длительность выполнения, и надо дождаться полного завершения вышестоящего объекта, видимо, при завершении воркфлоу (организация->репозиторий->воркфлоу->воркфлоуран->джоб->шаг).

2. Использование временных меток и меток метрик

    Временные метки (timestamps): Все данные будут передаваться с точными временными метками, полученными от GitHub, чтобы избежать расхождений между локальными и серверными таймстемпами.
    Метки метрик (labels): Будут использованы идентичные метки (например, job, workflow_id, status) для каждой метрики, чтобы обеспечить дедупликацию данных в кластере VictoriaMetrics и возможность детализированного анализа.

3. Очистка объектов в памяти

    Стратегия очистки:
        Комбинированный подход: Использовать очистку по событиям (например, по завершению воркфлоу), дополненную периодической очисткой при подтвержденной передаче в систему мониторинга и резервным TTL, чтобы предотвратить переполнение памяти.
        Контроль памяти: Периодически отслеживать потребление памяти с использованием пакета runtime и при достижении определённого лимита очищать наиболее старые объекты. Проверку проводить именно по текущему неймспейсу, где работает наш процесс.

4. План по разработке программы сбора метрик

    Асинхронная обработка данных: Планируется использовать асинхронные очереди или процессы для обработки данных из вебхуков и API, чтобы минимизировать блокировки и повысить производительность. Обращения к API используются для добора только пропущенных метрик после рестарта или других инцидентов. Основной источник данных — вебхуки. Но методы для обработки получаемых данных должны быть максимально универсальными (насколько это возможно в условиях разницы между данными из разных источников) и поддерживать оба источника.

    Очистка объектов при достижении лимита памяти: Планирую использовать структуру данных, такую как очередь с приоритетами, для удаления наиболее старых объектов, если достигнут указанный предел потребления памяти.

5. Дедупликация данных и повторное восстановление метрик

    VictoriaMetrics поддерживает дедупликацию данных при условии, что временные метки и метки метрик идентичны. Поэтому будет возможно безопасно добирать пропущенные метрики из API после рестарта и передавать их в систему.

    В случае сбоя или задержек буду использовать точные серверные временные метки из вебхуков и API, чтобы передавать метрики "из прошлого".

6. Стратегия записи метрик в хранилище

    Планирую использовать API VictoriaMetrics для отправки данных в систему хранения метрик, чтобы обеспечить надежную и эффективную запись данных.

    При успешной отправке данных в VictoriaMetrics буду очищать объекты из памяти, чтобы предотвратить переполнение памяти и повторную отправку данных. Для этого будут скидываться TTL на объекты, которые были успешно отправлены, чтобы быстрее поставить их в очередь на удаление.
    
    Отправлять будут через /metrics и /push API. /metrics отображается всегда, по всем тем объектам, которые есть в памяти и у которых не истек TTL. Если не указано куда пушить, то буду использовать только /metrics, если указано, то и /push, и /metrics. В случае успешной активной отправки через пуш, буду удалять объекты из памяти.

    Основное что буду хранить, это время начала и окончания воркфлоу, джоба, шага, статус выполнения, идентификаторы объектов, их названия и прочие метаданные. Но возможно еще буду вычислять дополнительные метрики, например, время выполнения, количество ошибок, и т.д., для более эффективного мониторинга и анализа.


 Для начала мы реализуем только три вида webhook events: workflow_dispatch; workflow_job; workflow_run (https://docs.github.com/en/webhooks/webhook-events-and-payloads).